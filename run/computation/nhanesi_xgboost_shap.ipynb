{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHANES I â€” XGBoost SHAP Computation\n",
    "\n",
    "This notebook trains an XGBoost survival model on the **NHANES I** dataset and computes SHAP values and SHAP interaction values for model explainability. The results are saved to disk for downstream visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Workspace\\shap-graph\\shap-graph-python\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import xgboost\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "Load the NHANES I survival dataset from the `shap` library and persist the feature matrix as a pickle for reuse in visualization notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shap.datasets.nhanesi()\n",
    "X.to_pickle(\"../../nhanesi/data/x_values.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "\n",
    "Split the data into 80% training and 20% test sets and wrap them in `xgboost.DMatrix` objects required by the XGBoost API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_full = xgboost.DMatrix(X, label=y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgboost.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the XGBoost survival model\n",
    "\n",
    "Train an XGBoost model with the Cox proportional-hazards objective (`survival:cox`) on the **full** dataset for 5 000 boosting rounds with a low learning rate (0.002) and 50% row subsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-cox-nloglik:9.28400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttest-cox-nloglik:8.60868\n",
      "[2000]\ttest-cox-nloglik:8.53110\n",
      "[3000]\ttest-cox-nloglik:8.49458\n",
      "[4000]\ttest-cox-nloglik:8.47055\n",
      "[4999]\ttest-cox-nloglik:8.45201\n"
     ]
    }
   ],
   "source": [
    "params = {\"eta\": 0.002, \"max_depth\": 3, \"objective\": \"survival:cox\", \"subsample\": 0.5}\n",
    "model = xgboost.train(params, xgb_full, 5000, evals=[(xgb_full, \"test\")], verbose_eval=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute SHAP values\n",
    "\n",
    "Use `shap.TreeExplainer` to compute SHAP values for the first 500 patients and save them to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patients = 500\n",
    "X_shapley = X.iloc[:num_patients, :]\n",
    "explainer = shap.TreeExplainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_shapley)\n",
    "np.save(\"../../data/nhanesi/xgboost/shap_values.npy\", shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute SHAP interaction values\n",
    "\n",
    "Compute pairwise SHAP interaction values for the same 500 patients. These capture feature-pair synergies and redundancies and are saved for network-based visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_interaction_values = explainer.shap_interaction_values(X_shapley)\n",
    "np.save(\"../../data/nhanesi/xgboost/shap_interaction_values.npy\", shap_interaction_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
